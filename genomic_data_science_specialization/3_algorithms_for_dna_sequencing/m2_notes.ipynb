{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: Preprocessing, indexing and approximate matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact matching: online algorithms\n",
    "\n",
    "Online algorithms don't process the text `t`, but some process the pattern `p`.\n",
    "\n",
    "### Naive exact matching\n",
    "\n",
    "* compares pattern `p` to every offset in the text `t`\n",
    "\n",
    "* lots of comparisons = very slow an inefficient\n",
    "\n",
    "### Boyer-Moore exact matching\n",
    "\n",
    "* an efficient string-searching algorithm\n",
    "* preprocesses the pattern **P** (the string being searched for), but not the text **T** (the string being searched in)\n",
    "* well-suited for applications in which the pattern is much shorter than the text or where it persists across multiple searches\n",
    "* uses information gathered during the preprocess step to skip sections of the text\n",
    "* for each alignment the last character in P is compared first\n",
    "\n",
    "#### Bad character rule\n",
    "\n",
    "* considers the character in T at which the comparison process failed (assuming such a failure occurred)\n",
    "* upon missmatch, skip alignments until the missmatch becomes a match or pattern moves past missmatched character.\n",
    "\n",
    "E.g. \n",
    "\n",
    "alignment 1: missmatch\n",
    "```\n",
    "T: GCTTCTGCTACCTTTT\n",
    "P: CCTTTTGC\n",
    "       xâœ“âœ“âœ“\n",
    "```\n",
    "\n",
    "alignment 2: still a missmatch - skip\n",
    "```\n",
    "T: GCTTCTGCTACCTTTT\n",
    "P:  CCTTTTGC\n",
    "       x\n",
    "```\n",
    "\n",
    "alignment 3: still a missmatch - skip\n",
    "```\n",
    "T: GCTTCTGCTACCTTTT\n",
    "P:   CCTTTTGC\n",
    "       x\n",
    "```\n",
    "\n",
    "alignment 4: match - do not skip\n",
    "```\n",
    "T: GCTTCTGCTACCTTTT\n",
    "P:    CCTTTTGC\n",
    "       âœ“\n",
    "```\n",
    "\n",
    "#### Good suffix rule\n",
    "\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact matching: index assisted offline algorithms\n",
    "\n",
    "Offline algorithms do process the text `t`.\n",
    "\n",
    "### K-mer indexing\n",
    "\n",
    "* `k`-mer = substring of `t` of length `k`\n",
    "\n",
    "* For every `k`-mer in `t`, record the index (aka the offset) where it occurs in `t`\n",
    "\n",
    "* For a given pattern `p` can find all the offsets where `p` occurs in `t` using the `k`-mer index\n",
    "\n",
    "  * e.g. take the first `k`-mer in `p` and look it up in the index\n",
    "\n",
    "  * e.g. if a match is found at offset `i` then we know that `p[:k] == t[i:i+k]`\n",
    "  \n",
    "  * next need to verify that the rest of `p` also matches `t` - i.e. we need to check that `p[k:] == t[i+k:i+len(p)]`\n",
    "\n",
    "#### Implementation\n",
    "\n",
    "I.e. how to actually find the offset in the index for a given k-mer.\n",
    "\n",
    "* binary search (e.g. using bisect module)\n",
    "\n",
    "* hash table (e.g. dictionary)\n",
    "\n",
    "#### Variations\n",
    "\n",
    "* build the index using every nth k-mer from `t`\n",
    "  * e.g. use every k-mer with and even offset\n",
    "    * need to query the index twice - e.g. using k-mers in `p` with offsets `i` and `i+1`\n",
    "  * e.g. use every 3rd k-mer\n",
    "    * need to query the index 3 times - e.g using k-mers in `p` with offsets `i`, `i+2` and `i+4`\n",
    "\n",
    "* build the index using subsequences instead of substrings\n",
    "  * a subsequence of S = a string of characters that also occurs in S in the same order, but not necessarily consecutively.\n",
    "    * e.g. `'ABC'` is a subsequence of `'xxxAxxxBxxxCxxx'`\n",
    "  * a substring is a special case of a subsequence where the characters are consecutive\n",
    "    * therefore all strings are subsequences\n",
    "    * but not all subsequences are substrings!\n",
    "  * this method tends to increase the specificity of the filter provided by the index compared to the method that uses substrings - i.e. index hits lead to successful verifications more of the time (is this really true?)\n",
    "\n",
    "### Other kinds of indexing using in genomics\n",
    "\n",
    "* suffix tree\n",
    "\n",
    "* suffix array\n",
    "\n",
    "* fm index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate matching\n",
    "\n",
    "Good reasons to expect differences between the read and the reference genome:\n",
    "\n",
    "* sequencing errors\n",
    "\n",
    "* reference genome might be different from the genome being studied\n",
    "\n",
    "### Types of differences between strings\n",
    "\n",
    "* missmatch - aka substitution\n",
    "\n",
    "* insertion\n",
    "\n",
    "* deletion\n",
    "\n",
    "### Measurements of distance between strings\n",
    "\n",
    "#### Hamming distance\n",
    "\n",
    "* minimum number of substitutions needed to turn one string into the other\n",
    "\n",
    "* strings need to be the same length\n",
    "\n",
    "#### Edit distance (aka Levenstein distance)\n",
    "\n",
    "* minimum number of substitutions / insertions / deletions needed to turn one string into the other\n",
    "\n",
    "* strings don't need to be the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive(p, t):\n",
    "    occurrences = []\n",
    "    for i in range(len(t) - len(p) + 1):  # loop over alignments\n",
    "        match = True\n",
    "        for j in range(len(p)):  # loop over characters\n",
    "            if t[i+j] != p[j]:  # compare characters\n",
    "                match = False\n",
    "                break\n",
    "        if match:\n",
    "            occurrences.append(i)  # all chars matched; record\n",
    "    return occurrences\n",
    "\n",
    "def naive_hamming(p, t, max_distance):\n",
    "    occurrences = []\n",
    "    for i in range(len(t) - len(p) + 1):  # loop over alignments\n",
    "        match = True\n",
    "        n_mis_match = 0\n",
    "        for j in range(len(p)):  # loop over characters\n",
    "            if t[i+j] != p[j]:  # compare characters\n",
    "                n_mis_match += 1\n",
    "                if n_mis_match > max_distance:\n",
    "                    match = False\n",
    "                    break\n",
    "        if match:\n",
    "            occurrences.append(i)  # all chars matched; record\n",
    "    return occurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pigeonhole principle\n",
    "\n",
    "Allows us to apply exact matching algorithms to approximate matching problems\n",
    "\n",
    "* E.g. if we want to allow a maximum of 1 edit when matching `p` to `t`\n",
    "    * if we split `p` into 2 partitions then at least one of those partitions must match `t` exactly\n",
    "\n",
    "* E.g. if we want to allow a maximum of `n` edits when matching `p` to `t`\n",
    "    * if we split `p` into `n+1` partitions then at least one of those partitions must match `t` exactly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def partition_string1(x, n):\n",
    "    assert n > 0\n",
    "    assert n <= len(x)\n",
    "    partitions = []\n",
    "    partition_size = round(len(x) / n)\n",
    "    for i in range(n):\n",
    "        start = i * partition_size\n",
    "        end = min((i+1) * partition_size, len(x))\n",
    "        partitions.append(x[start:end])\n",
    "    return partitions\n",
    "\n",
    "def partition_string2(x, n):\n",
    "    assert n > 0\n",
    "    assert n <= len(x)\n",
    "    partitions = []\n",
    "    partition_size = math.ceil(len(x) / n)\n",
    "    for i in range(n):\n",
    "        start = i * partition_size\n",
    "        end = min((i+1) * partition_size, len(x))\n",
    "        partitions.append(x[start:end])\n",
    "    return partitions\n",
    "\n",
    "import textwrap\n",
    "\n",
    "def partition_string3(x, n):\n",
    "    assert n > 0\n",
    "    assert n <= len(x)\n",
    "    partition_size = round(len(x) / n)\n",
    "    return textwrap.wrap(x, partition_size)\n",
    "\n",
    "def partition_string4(x, n):\n",
    "    assert n > 0\n",
    "    assert n <= len(x)\n",
    "    partition_size = math.ceil(len(x) / n)\n",
    "    return textwrap.wrap(x, partition_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12345678901234567890'],\n",
       " ['1234567890', '1234567890'],\n",
       " ['1234567', '8901234', '567890'],\n",
       " ['12345', '67890', '12345', '67890'],\n",
       " ['1234', '5678', '9012', '3456', '7890'],\n",
       " ['123', '456', '789', '012', '345', '678'],\n",
       " ['123', '456', '789', '012', '345', '678', '90'],\n",
       " ['12', '34', '56', '78', '90', '12', '34', '56'],\n",
       " ['12', '34', '56', '78', '90', '12', '34', '56', '78'],\n",
       " ['12', '34', '56', '78', '90', '12', '34', '56', '78', '90']]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = '12345678901234567890'\n",
    "[partition_string1(x, i) for i in [1,2,3,4,5,6,7,8,9,10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12345678901234567890'],\n",
       " ['1234567890', '1234567890'],\n",
       " ['1234567', '8901234', '567890'],\n",
       " ['12345', '67890', '12345', '67890'],\n",
       " ['1234', '5678', '9012', '3456', '7890'],\n",
       " ['1234', '5678', '9012', '3456', '7890', ''],\n",
       " ['123', '456', '789', '012', '345', '678', '90'],\n",
       " ['123', '456', '789', '012', '345', '678', '90', ''],\n",
       " ['123', '456', '789', '012', '345', '678', '90', '', ''],\n",
       " ['12', '34', '56', '78', '90', '12', '34', '56', '78', '90']]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[partition_string2(x, i) for i in [1,2,3,4,5,6,7,8,9,10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12345678901234567890'],\n",
       " ['1234567890', '1234567890'],\n",
       " ['1234567', '8901234', '567890'],\n",
       " ['12345', '67890', '12345', '67890'],\n",
       " ['1234', '5678', '9012', '3456', '7890'],\n",
       " ['123', '456', '789', '012', '345', '678', '90'],\n",
       " ['123', '456', '789', '012', '345', '678', '90'],\n",
       " ['12', '34', '56', '78', '90', '12', '34', '56', '78', '90'],\n",
       " ['12', '34', '56', '78', '90', '12', '34', '56', '78', '90'],\n",
       " ['12', '34', '56', '78', '90', '12', '34', '56', '78', '90']]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[partition_string3(x, i) for i in [1,2,3,4,5,6,7,8,9,10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12345678901234567890'],\n",
       " ['1234567890', '1234567890'],\n",
       " ['1234567', '8901234', '567890'],\n",
       " ['12345', '67890', '12345', '67890'],\n",
       " ['1234', '5678', '9012', '3456', '7890'],\n",
       " ['1234', '5678', '9012', '3456', '7890'],\n",
       " ['123', '456', '789', '012', '345', '678', '90'],\n",
       " ['123', '456', '789', '012', '345', '678', '90'],\n",
       " ['123', '456', '789', '012', '345', '678', '90'],\n",
       " ['12', '34', '56', '78', '90', '12', '34', '56', '78', '90']]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[partition_string4(x, i) for i in [1,2,3,4,5,6,7,8,9,10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_match(p, t, n):\n",
    "    # divide p into n+1 segments - at least 1 must match perfectly against t\n",
    "    segment_length = round(len(p) / (n+1))\n",
    "    all_matches = set()\n",
    "    for i in range(n+1):\n",
    "        start = i * segment_length\n",
    "        end = min((i+1) * segment_length, len(p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
